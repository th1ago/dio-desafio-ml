{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "# valores de tempo de execucao da rede\n",
    "from time import time \n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() #definindo a conversao de imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) #carrega a parte de treino do datasets\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #carrega um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) #carrega a parte de validacao do dataset\n",
    "valloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #cria buffer para pegar os dados por partes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d41babbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = next(dataiter)\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) #para verificar as dimensoes do tensor de cada imagem\n",
    "print(etiquetas[0].shape) #para verificar as dimensoes do tensor de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) #camada de entrada, 784 neuronios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(28*28, 128) #camada interna 1, 128 neuronios que se ligam a 63\n",
    "        self.linear3 = nn.Linear(28*28, 128) #camada interna 2, 64 neuronios que se ligam a 10\n",
    "        #para a camada de saida nao e necessario definir nada pois so precisam pegar o output da camada interna 2\n",
    "\n",
    "    def foward(self, X):\n",
    "        X = F.relu(self.linear1(X)) #funcao de ativacao da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X)) #funcao de ativacao da camada interna 1 para a camada interna 2\n",
    "        X = self.linear3(X) #funcao de ativacao da camada interna 2 para a camada de saida, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) #dados utilizado para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #define a politica de atualizacao dos pesos e da bias\n",
    "    inicio = time() #timer para sabermos quanto tempo levou o treino\n",
    "\n",
    "    criterio = nn.NLLLoss() #definindo o criteiro para calcular a perda\n",
    "    EPOCHS = 10 #numero de epochs que o algoritmo rodara\n",
    "    modelo.train() #ativando o modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 #inicializacao da perda acumulada da epoch em questao\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "            imagens = imagens.view(imagens.shape[0], -1) #converte as imagens para \"vetores\" de 28*28 casas para ficarem compativeis \n",
    "            otimizador.zero_grad() #zerando os gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) #colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) #calculando a perda de epoch em questao\n",
    "\n",
    "            perda_instantanea.backward() #back propagation a partir da perda\n",
    "\n",
    "            otimizador.step() #atualizando os pesos da bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() #atualizacao da perda acumulada\n",
    "\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\nTempo de treino (em minutos) =\", (time() - inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            #desativa o autograd para acelerar a validacao. Grafos computacionais dinamicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                loggps = modelo(img.to(device)) #output do modelo em escala logaritmica\n",
    "\n",
    "            ps = torch.exp(loggps) #converte output para escala normal(um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max[probab]) #converte o tensor em um numero, o numero que o modelo previu como correto\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if(etiqueta_certa == etiqueta_pred):\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "        \n",
    "        print(\"Total de imagens testadas =\", conta_todas)\n",
    "        print(\"\\nPrevisao do modelo={}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=784, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "336295d508b094686eaf9f75dae8800c5c8c863f253658ee66d2acca65590102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
